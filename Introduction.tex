\sgcomment{We write here about 
\begin{enumerate}
    \item Stackelberg games including history (Refer to 1934 paper by Stackelberg); comparison with Nash equilibrium and state that Stackelberg strategy may produce greater payoff for the leader than in the Nash equilibrium.
    \item application of Stackelberg games
\end{enumerate}}

Stackelberg games were first introduced by German economist Heinrich Freiherr von Stackelberg in his book \textit{Marktform und Gleichgewicht} in 1934 \cite{S34} to better simulate how firms behave in the market. The players of this game comprise of a leader firm and follower firms. The leader starts the game by announcing her strategy and the followers respond by playing the optimal reponse to the leader's strategy.

Let us demonstrate why Stackelberg Equilibria produce a better payoff than their Nash counterparts with an example. Consider the period of 1894 - 1999 where the motorcycle manufacturers were in a competition to produce the fastest production motorcycle. After over a century of one-upmanship, some regulators and politicians in Europe, fearing an outbreak of illegal racing as riders try to break the 200 mph barrier, called for an import ban against high speed motorcycles. To preempt regulation and avoid negative publicity, the manufacturers voluntarily entered into a \text{Gentlemen's agreement} to limit the speed of their machines to 300 kmph (186 mph), starting with 2000 models. A Nash strategy suggests that each company must break the agreement to produce a faster motorcycle, thus getting a higher market share. But breaking the agreement would likely result in an import ban regulation which would imply a huge market loss for all manufacturers involved. On the other hand, a Stackelberg strategy would explain why that no company must break the agreement, and thus would ideally yield equal market share for all motorcycle companies involved.\cite{WIKI00}

In this paper, we study the notion of Stackelberg Equilibria on two-player non-zero sum infinite duration mean-payoff games played on graph arenas. We note $\Sigma_0$ the set of strategies of Player~0, also called the leader, and $\Sigma_1$ the set of strategies of Player~1, also called the follower. Additionally,
the game comes with two (usually $\mathbb{R}$-valued) mean-payoff functions, $\mathbf{MP}_0$ and $\mathbf{MP}_1$, that determine the payoff each player receives: if $\sigma_0 \in \Sigma_0$ and $\sigma_1 \in \Sigma_1$ are chosen then Player~0 receives the payoff $\mathbf{MP}_0 (\mathsf{Out}(\sigma_0$, $\sigma_1))$ while Player~1 receives the payoff $\mathbf{MP}_1(\mathsf{Out}(\sigma_0$, $\sigma_1))$, where $\mathsf{Out}(\sigma_0$, $\sigma_1)$ refers to the play which is the outcome of Player~0 and Player~1 playing their respective strategies. Both players aim at maximizing their respective payoffs. As mentioned before, in a Stackelberg game, players play sequentially as follows.
\begin{inparaenum}[(i)]
\item Player~0, the leader, announces her choice of strategy $\sigma_0 \in \Sigma_0$. 
\item Player~1, the follower, announces his choice of strategy $\sigma_1 \in \Sigma_1$ in response to the leader's strategy. 
\item Both players receive their respective payoffs: $\mathbf{MP}_0 (\mathsf{Out}(\sigma_0$, $\sigma_1))$ and $\mathbf{MP}_1 (\mathsf{Out}(\sigma_0$, $\sigma_1))$.
\end{inparaenum}
Due to the sequential nature of the game, Player~1 knows the strategy $\sigma_0$, and so to act rationally (s)he should choose a strategy $\sigma_1$ that maximizes the payoff $\mathbf{MP}_1 (\mathsf{Out}(\sigma_0$, $\sigma_1))$. If such a strategy $\sigma_1$ exists, it is called a best-response to the strategy $\sigma_0 \in \Sigma_0$.
In this paper, we assume that Player~1 is not completely rational, thus choosing an $\epsilon$-optimal best-response to the strategy $\sigma_0 \in \Sigma_0$. In \cite{FGR20}, we establish that there always exists an $\epsilon$-optimal best response for Player~1 to any strategy $\sigma_0 \in \Sigma_0$ of Player~0.
In turn, if the leader assumes an almost-rational response of the follower to her strategy, this should guide the leader when choosing $\sigma_0 \in \Sigma_0$.
Indeed, the leader should choose a strategy $\sigma_0 \in \Sigma_0$ such that the value $\mathbf{MP}_0 (\mathsf{Out}(\sigma_0$, $\sigma_1))$ is as large as possible when $\sigma_1$ is an $\epsilon$-optimal best-response of the follower.

Two different scenarios can be considered in this setting: either the best-response $\sigma_1 \in \Sigma_1$ is imposed by the leader (or equivalently chosen cooperatively by the two players), or the best-response is chosen adversarially by Player~1. But, the adversarial case is more interesting because it allows us to model the situation in which the leader can only choose $\sigma_0 \in \Sigma_0$ and must be prepared to face any almost rational response of Player~1, i.e. if Player~1 has several possible $\epsilon$-best responses then $\sigma_0$ should be designed to face all of them. In this paper, our main contribution is to investigate the second route.

\textbf{Related Work} In \cite{FKL10}, we study the notion of rational synthesis in the co-operative setting, whereas in \cite{KPV16}, we study the notion of rational synthesis in adversarial setting. In \cite{CFGR16}, we study the complexity of rational synthesis for various omega-regular objectives in both the adversarial and co-operative setting. In \cite{GS14}, we study multi-player mean-payoff Stackelberg games in the co-operative setting (here the leader assigns strategies to herself and her followers). In \cite{GS18}, we study bi-matrix Stackelberg games in both co-operative and adversarial setting. In \cite{GSTDP16}, we study the concept of Incentive Stackelberg mean-payoff games, where in addition to assigning strategies to all players, the leader can also transfer parts of her payoff to other players to incentivise them to follow the assigned strategy. In \cite{CHJ06}, we study the concept of Secure Equilibria in two-player non-zero sum games where the players are adversarial.  This is very similar to Adversarial Stackelberg Equilibria but in Secure Equilibria, there exists no leader player.  In \cite{PFKSV14}, we study Secure Equilibrium in multi-player games.  In \cite{GS15}, we study the effects of limited memory on both Nash and Stackelberg Equilibria in Multi-player discounted sum games. In \cite{FGR20}, we study Stackelberg Mean-Payoff Games in adversarial setting and  Stackelberg Discount Sum Games in both adversarial and co-operative setting.

\sgcomment{{\bf Related Work} We should look at the following papers:
\begin{enumerate}
    \item Dana Fisman, Orna Kupferman, and Yoad Lustig. Rational synthesis. (Even these papers possibly talk about the cooperative setting, and not the adversarial setting.)
    \item Orna Kupferman, Giuseppe Perelli, and Moshe Y. Vardi. Synthesis with rational environments.
    \item Rodica Condurache, Emmanuel Filiot, Raffaella Gentilini, and Jean-François Raskin. The complexity of rational synthesis.
    \item Emmanuel Filiot, Raffaella Gentilini, and Jean-François Raskin. Rational synthesis under imperfect information. \mbcomment{(If it is imperfect information, it is not Stackelberg as P0 announces strategy, right?)}
    \item Anshul Gupta and Sven Schewe. Quantitative verification in rational environments.
    \item Anshul Gupta, Sven Schewe. Buying Optimal Payoffs in Bi-Matrix Games
    \item Anshul Gupta, Sven Schewe, Ashutosh Trivedi, Maram Sai Krishna Deepak, and Bharath Kumar Padarthi. Incentive stackelberg mean-payoff games.
    \item \mbcomment{We should also look at the literature for stochastic Stackelberg games}
    \item Krishnendu Chatterjee, Thomas A. Henzinger, Marcin Jurdzinski. Games with Secure Equilibria
    \item Julie De Pril, János Flesch, Jeroen Kuipers, Gijs Schoenmakers, Koos Vrieze. Existence of Secure Equilibrium in Multi-player Games with Perfect Information
    \item Anshul Gupta, Sven Schewe, and Dominik Wojtczak. Making the best of limited memory in multi-player discounted sum games
    \item Emmanuel Filiot, Raffaella Gentilini, and Jean-François Raskin. The Adversarial Stackelberg Value in Quantitative Games
\end{enumerate}}

\textbf{\bf Our contribution} We first show that, in general, infinite memory is required for Player 0 to achieve the $\mathbf{ASV}^{\epsilon}$. This is true for achieving $\mathbf{ASV}$ as well, as show in \cite{FGR20}. We also show that $\epsilon$-optimal best-responses of Player 1 may require infinite memory. Similar to the results in \cite{FGR20}, we introduce a notion of $\epsilon$-witness for proving that $\mathbf{ASV}^{\epsilon}$ is greater than some threshold and show that a finite memory strategy, which can be found in $\mathsf{NP}$-time, is sufficient to achieve this threshold. Furthermore, we describe an $\mathsf{EXP}$-time algorithm to compute the $\mathbf{ASV}^{\epsilon}$, which is in a improvement (time-wise) on the algorithm to compute $\mathbf{ASV}$ in \cite{FGR20}. Additionally, we provide an improvement on the $\mathsf{NP}$-time algorithm for threshold problem in \cite{FGR20} and show that a finite memory strategy is sufficient to achieve $\mathbf{ASV} > c$. In contrast to the results in \cite{FGR20}, we show that $\mathbf{ASV}^{\epsilon}$ is always achievable.

\textbf{Structure of the Paper} In \cref{sec:prelim}, we introduce the necessary preliminaries for our definitions and developments. In \cref{sec:examples}, we examine the memory requirements of both players for playing their strategies. In \cref{sec:ThresholdProblem}, we consider the threshold problem, i.e. checking if $\mathbf{ASV}^{\epsilon} > c$. In \cref{sec:ComputeASV}, we present an algorithm to compute the $mathbf{ASV}^{\epsilon}$. In \cref{sec:FMASV}, we present a memory improvement for a previous result established in \cite{FGR20}. In \cref{sec:Achievability}, we show that the $\mathbf{ASV}^{\epsilon}$ is always achievable.