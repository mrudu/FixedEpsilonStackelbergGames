\sgcomment{We write here about 
\begin{enumerate}
    \item Stackelberg games including history (Refer to 1934 paper by Stackelberg); comparison with Nash equilibrium and state that Stackelberg strategy may produce greater payoff for the leader than in the Nash equilibrium.
    \item application of Stackelberg games
\end{enumerate}}

Stackelberg games were introduced by German economist Heinrich Freiherr von Stackelberg in \cite{S34} to simulate how firms behave in the market. The players of this game comprise of one leader firm and multiple follower firms. The leader starts the game by announcing her strategy and the followers respond by playing the optimal response to the leader's strategy.

% Let us demonstrate why Stackelberg Equilibria produce a better payoff than their Nash counterparts with an example. Consider the period of 1894 - 1999 where the motorcycle manufacturers were in a competition to produce the fastest production motorcycle. After over a century of one-upmanship, some regulators and politicians in Europe, fearing an outbreak of illegal racing as riders try to break the 200 mph barrier, called for an import ban against high speed motorcycles. To preempt regulation and avoid negative publicity, the manufacturers voluntarily entered into a \text{Gentlemen's agreement} to limit the speed of their machines to 300 kmph (186 mph), starting with 2000 models. A Nash Equilibrium strategy would suggest that each company must break the agreement to produce a faster motorcycle, thus getting a higher market share. But breaking the agreement would likely result in an import ban regulation which would imply a huge market loss for all manufacturers involved. On the other hand, a Stackelberg Equilibrium strategy would explain why that no company must break the agreement, and thus would ideally yield equal market share for all motorcycle companies involved.\cite{WIKI00}

\begin{figure}
    \centering
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.8cm,
                        semithick, squarednode/.style={rectangle, draw=blue!60, fill=blue!5, very thick, minimum size=15mm}]
      \tikzstyle{every state}=[fill=white,draw=black,text=black,minimum size=2cm]
    
      \node[squarednode]                                                 (A)              {$v_0$};
      \node[state, draw=red!60, fill=red!5]                              (B) [left of=A]  {$v_2$};
      \node[state, draw=red!60, fill=red!5]                              (C) [right of=A] {$v_1$};
      \node[draw=none, fill=none, minimum size=0cm, node distance = 2cm] (D) [above of=A] {$start$};
      \node[state, draw=red!60, fill=red!5]                              (E) [left of=B]  {$v_3$};
      \path (A) edge              node {(1,2)} (B)
                edge              node {(0,1)} (C)
            (B) edge [loop above] node {(1,2)} (B)
                edge              node {(2,0)} (E)
            (C) edge [loop above] node {(0,1)} (C)
            (E) edge [loop above] node {(2,0)} (E)
            (D) edge [left] node {} (A);
    \end{tikzpicture}
    \caption{An example in which Stackelberg equilibrium for Player $0$ gives better payoff than Nash equilibrium.}
    \label{fig:nash_vs_stackelberg}
\end{figure}

We demonstrate here with a mean-payoff game example why Stackelberg Equilibrium produces a better payoff for the leader than a Nash equilibrium strategy. Consider the example depicted in \cref{fig:nash_vs_stackelberg} where there is one leader player (blue circle) and one follower player (red square). In this game, the dominant strategy for the leader, $\sigma_L^{\mathsf{Nash}}$, is to play $v_2 \to v_3$. In this case, the follower will respond with the strategy, $\sigma_F^{\mathsf{Nash}}$, where he plays $v_0 \to v_1$. The strategy profile ($\sigma_L^{\mathsf{Nash}}$, $\sigma_F^{\mathsf{Nash}}$) is in Nash Equilibrium and yields a payoff of 0 to the leader. However, if the leader announces a strategy $\sigma_L^{\mathsf{Stackelberg}}$ where she plays $v_2 \to v_2$, the follower will get a better payoff if he responds with a strategy $\sigma_F^{\mathsf{Stackelberg}}$ where he plays $v_0 \to v_2$. Thus, the strategy profile ($\sigma_L^{\mathsf{Stackelberg}}$, $\sigma_F^{\mathsf{Stackelberg}}$) is in Stackelberg Equilibrium and yields a payoff of 1 to the leader.

\begin{figure}
    \centering
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.8cm,
                        semithick, squarednode/.style={rectangle, draw=blue!60, fill=blue!5, very thick, minimum size=15mm}]
      \tikzstyle{every state}=[fill=white,draw=black,text=black,minimum size=2cm]
    
      \node[squarednode]                                                 (A)              {$v_0$};
      \node[state, draw=red!60, fill=red!5]                              (B) [left of=A]  {$v_2$};
      \node[state, draw=red!60, fill=red!5]                              (C) [right of=A] {$v_1$};
      \node[draw=none, fill=none, minimum size=0cm, node distance = 2cm] (D) [above of=A] {$start$};
      \node[state, draw=red!60, fill=red!5]                              (E) [left of=B]  {$v_3$};
      \path (A) edge              node {(1,2)} (B)
                edge              node {(0,1)} (C)
            (B) edge [loop above] node {(1,1)} (B)
                edge              node {(2,0)} (E)
            (C) edge [loop above] node {(0,1)} (C)
            (E) edge [loop above] node {(2,0)} (E)
            (D) edge [left] node {} (A);
    \end{tikzpicture}
    \caption{Cooperative Stackelberg Equilibrium vs Adversarial Stackelberg Equilibrium}
    \label{fig:cooperative_vs_adversarial}
\end{figure}

Thus, we can see that the leader with the power to communicate her strategy can incentivise the follower to play a strategy which she desires and thereby get a better payoff. Both the leader and the follower aim at maximising their respective payoffs. However, the follower can have multiple optimal responses to the leader's strategy. Two different scenarios can be considered in this setting: either the optimal-response strategy is imposed by the leader (or equivalently chosen cooperatively by the two players), or the optimal-response strategy is chosen adversarially by the follower. We demonstrate the two scenarios with an example depicted in \cref{fig:cooperative_vs_adversarial}. Similar to the previous example in \cref{fig:nash_vs_stackelberg}, the leader can announce her strategy $\sigma_L$ where she plays $v_2 \to v_2$. However, in this example the follower has two optimal responses, i.e. he can play $v_0 \to v_1$ or $v_0 \to v_2$. If the follower is co-operative, then he will choose the strategy which also maximises the leader's payoff. In this example, the co-operative follower will choose to play the strategy $v_0 \to v_2$. Thus, in the cooperative setting, the leader receives a payoff of 2 and the follower receives a payoff of 1. But if the follower is adversarial, he will choose the strategy which minimises the payoff of the leader. In this example, the adversarial follower will choose to play $v_0 \to v_1$. Thus, in the cooperative setting, the leader receives a payoff of 0 and the follower receives a payoff of 1.

The adversarial case is more interesting because it allows us to model the situation in which the leader can only choose her strategy and must be prepared to face any rational response of follower, i.e. if follower has several possible optimal responses then the leader's strategy should be designed to face all of them.

In this paper, we study the notion of Adversarial Stackelberg Equilibria on two-player non-zero sum infinite duration mean-payoff games played on graph arenas. Here, the two players are the leader, also called Player~0 and the follower, also called Player~1. The game comes with two (usually $\mathbb{R}$-valued) mean-payoff functions that determine the payoff each player receives. As mentioned before, in a Stackelberg game, players play sequentially as follows.
\begin{inparaenum}[(i)]
\item Player~0, the leader, announces her choice of strategy $\sigma_0$. 
\item Player~1, the follower, announces his choice of strategy $\sigma_1$ in response to the leader's strategy $\sigma_0$. 
\item Both players receive their respective mean-payoffs determined by their respective mean-payoff functions.
\end{inparaenum}
Due to the sequential nature of the game, Player~1 knows the strategy $\sigma_0$, and so to act rationally (s)he should choose a strategy that maximises his payoff. If such a strategy exists, it is called a best-response to Player~0's strategy $\sigma_0$. However, best-responses are not guaranteed to always exist \cite{FGR20}. Thus, we introduce the concept of $\epsilon$-optimal best responses. Here, the follower, i.e., Player~1  plays any strategy that gives him a payoff that is up to an $\epsilon$ amount lesser than the best payoff he can receive. In \cite{FGR20}, we establish that there always exists an $\epsilon$-optimal best response for Player~1 for every strategy of Player~0. 

In this paper, we assume that Player~1 is not completely rational, and hence Player~1 would always choose an $\epsilon$-optimal best-response to Player~0's strategy $\sigma_0$
In turn, if the leader assumes an almost-rational response of the follower to her strategy, this should guide the leader when choosing her strategy $\sigma_0$.

Indeed, the leader should choose a strategy $\sigma_0 $ such that payoff she receives is as large as possible when the follower plays an adversarial $\epsilon$-optimal best-response. We call the payoff obtained by the leader when she plays such a strategy as the $\epsilon$-optimal Adversarial Stackelberg Value, or simply, the $\mathbf{ASV}^{\epsilon}$.

\textbf{\bf Our contribution}

\begin{table}[]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
 &
  Threshold Problem &
  Computing ASV &
  Achievability \\ \hline
\begin{tabular}[c]{@{}c@{}}Adversarial \\ Follower\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}{\color[HTML]{009901} NP-Time} \\ \\ {\color[HTML]{FE0000} \textbf{Finite Memory}} \\ {\color[HTML]{FE0000} \textbf{Strategy}} \end{tabular} &
  {\color[HTML]{009901} Theory Of Reals} &
  {\color[HTML]{009901} No} \\ \hline
\begin{tabular}[c]{@{}c@{}}Adversarial\\ Epsilon-Optimal \\ Follower\end{tabular} &
  {\color[HTML]{FE0000} \textbf{\begin{tabular}[c]{@{}c@{}}NP-Time\\ \\ Finite Memory \\ Strategy\end{tabular}}} &
  {\color[HTML]{FE0000} \textbf{\begin{tabular}[c]{@{}c@{}}Theory Of Reals/\\ \\ Solving LP \\ in EXP-Time\end{tabular}}} &
  {\color[HTML]{FE0000} \textbf{\begin{tabular}[c]{@{}c@{}}Yes\\ \\ (Requires Infinite \\ Memory)\end{tabular}}} \\ \hline
\end{tabular}
\caption{
    {\color[HTML]{FE0000} \textbf{Results obtained in our work are in red and bold-text }} whereas {\color[HTML]{009901} Results obtained in \cite{FGR20} are in green and normal-text}
}
\label{tab:results}
\end{table}

In contrast with the work in \cite{FGR20}, we assume here that Player~1 is not completely rational, i.e., he is willing to get an $\epsilon$ amount lesser than the best payoff possible. 

We begin by showing that infinite memory is required for Player~0 to achieve the $\mathbf{ASV}^{\epsilon}$. This is similar to the result obtained in \cite{FGR20} which shows that the leader, Player~0, needs infinite memory to achieve $\mathbf{ASV}$. 

We also show that Player 1 may require infinite memory to play $\epsilon$-optimal best-responses. 

Similar to the results obtained in \cite{FGR20}, we introduce a notion of $\epsilon$-witness for proving that $\mathbf{ASV}^{\epsilon}$ is greater than some threshold . But here, we go a step further by developing a finite memory strategy for Player~0 to achieve this $\mathbf{ASV}^{\epsilon}$ threshold value. This finite memory strategy can be found in $\mathsf{NP}$-time. 

Furthermore, we describe an $\mathsf{EXP}$-time algorithm to compute the $\mathbf{ASV}^{\epsilon}$, which is in a improvement (time-wise) on the algorithm to compute $\mathbf{ASV}$ in \cite{FGR20}. Additionally, we provide an improvement on the $\mathsf{NP}$-time algorithm for threshold problem in \cite{FGR20} and show that a finite memory strategy is sufficient to achieve $\mathbf{ASV} > c$. In contrast to the results in \cite{FGR20}, we show that $\mathbf{ASV}^{\epsilon}$ is always achievable.

\textbf{Related Work} 

In \cite{FKL10}, the authors introduce the notion of rational synthesis in the co-operative setting for omega-regular objectives. In \cite{KPV16}, the authors study the notion of adversarial rational synthesis. In \cite{CFGR16}, the complexity of rational synthesis for various omega-regular objectives is established in both the adversarial and co-operative setting. In \cite{GS14}, the authors study multi-player mean-payoff Stackelberg games in the co-operative setting.

% In \cite{GS18}, we study Bi-Matrix Stackelberg games in both co-operative and adversarial setting. In \cite{GSTDP16}, we study the concept of Incentive Stackelberg mean-payoff games, where in addition to assigning strategies to all players, the leader can also transfer parts of her payoff to other players to incentivise to follow the assigned strategy. In \cite{CHJ06}, we study the concept of Secure Equilibrium in two-player non-zero sum games where the players are adversarial.  This is very similar to Adversarial Stackelberg Equilibrium but in the case of Adversarial Secure Equilibrium, there exists no leader player in the game. 

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
    \centering
    \begin{tabular}{ll|c|c|}
        \cline{3-4}
        & & \multicolumn{2}{c|}{Player I} \\ 
        \cline{3-4} 
        & & I & II \\ 
        \hline
        \multicolumn{1}{|c|}{\multirow{2}{*}{Player II}} & \multicolumn{1}{c|}{I}  & (1, 4) & (4, 2)\\ 
        \cline{2-4} 
        \multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{II} & (1, 3) & (3, 5) \\
        \hline
    \end{tabular}
    \caption{Example of Nash vs Stackelberg Equilibrium in a bi-matrix game}
    \label{tab:bi-matrix-game}
\end{table}
\track{In \cite{GS18}, the authors study both Stackelberg (leader) equilibrium and incentive equilibrium over bi-matrix games. It is not difficult to see that the leader can improve upon the payoff by providing an incentive to her follower which is actually a share of her own payoff. They define the leader strategy profile as one in which the follower cannot improve his payoff by deviating, and hence every Nash equlibrium is a leader strategy profile. A leader equilibrium is a leader strategy profile that gives the highest payoff to the leader. Every leader strategy profile is an incentive strategy profile with incentive value $0$. Since in this work, the authors consider mixed strategies, the existence of Nash equilibrium in bi-matrix games \cite{Nash50,LH64} implies the existence of leader and incentive equilibria.}

\track{In \cite{CHJ06}, the authors study secure Nash equilibrium, where the objectives are considered in a lexicographic order. The two players try to first maximise their own payoffs, and then minimize the payoff of the other player. A secure Nash equilibrium is a Nash equilibrium.}

We illustrate these equilibria stated above with the help of a bi-matrix game.
\sgcomment{Add the bi-matrix example from the slides}
Consider the bi-matrix game shown in \cref{tab:bi-matrix-game}. Considering pure strategy profiles, the only pure strategy Nash equilibrium (and thus a secure Nash equilibrium) is the profile (I, I), while the profile (II, II) is a leader equilibrium.

In \cite{GSTDP16}, the authors study the concept of Incentive Stackelberg mean-payoff games, where in addition to assigning strategies to all players, the leader can also transfer parts of her payoff to other players to incentivise to follow the assigned strategy. 

In \cite{PFKSV14}, the authors study Secure Equilibrium in multi-player games.  In \cite{GS15}, the authors study the effects of limited memory on both Nash and Stackelberg Equilibria in Multi-player discounted sum games. In \cite{FGR20}, the authors study Stackelberg Mean-Payoff Games in adversarial setting and  Stackelberg Discount Sum Games in both adversarial and co-operative setting.

\track{Adversarial Stackelberg games can be relevant in several contexts. Consider two belligerent countries, say $A$ and $B$ that are engaged in increasing their nuclear arsenal. There may be a country, let's say $A$ that is more powerful than the other. While both the countries are under mutual threat, however, it is likely that the less powerful country gets more seriously affected in the case of a war. So it is in the interest of the more powerful country to attack the less powerful one. On the other hand, any attack from the more powerful country $A$ on the other one may lead the country $B$ to stop exporting to $A$ some goods that are of high value to $A$. The resultant state models the situation of a Nash equilibrium . If the more powerful country, on the other hand, pledges to commit to a nuclear non-proliferation, and asks country $B$ to do the same, it is likely that the less powerful country will also follow the same, and both the countries save expenses on increasing their nuclear arsenal. However, still since the less powerful country $B$ does not have a cordial relation with country $A$, it will try to act in a way that harms  country $A$ whenever possible modelling the case of an Adversarial Stackelberg game.}

\track{In \cite{GS18}, the authors consider a class of Arms Race game as an example for incentive equilibrium.}


\sgcomment{{\bf Related Work} We should look at the following papers:
\begin{enumerate}
    \item Dana Fisman, Orna Kupferman, and Yoad Lustig. Rational synthesis. (Even these papers possibly talk about the cooperative setting, and not the adversarial setting.)
    \item Orna Kupferman, Giuseppe Perelli, and Moshe Y. Vardi. Synthesis with rational environments.
    \item Rodica Condurache, Emmanuel Filiot, Raffaella Gentilini, and Jean-François Raskin. The complexity of rational synthesis.
    \item Emmanuel Filiot, Raffaella Gentilini, and Jean-François Raskin. Rational synthesis under imperfect information. \mbcomment{(If it is imperfect information, it is not Stackelberg as P0 announces strategy, right?)}
    \item Anshul Gupta and Sven Schewe. Quantitative verification in rational environments.
    \item Anshul Gupta, Sven Schewe. Buying Optimal Payoffs in Bi-Matrix Games
    \item Anshul Gupta, Sven Schewe, Ashutosh Trivedi, Maram Sai Krishna Deepak, and Bharath Kumar Padarthi. Incentive stackelberg mean-payoff games.
    \item \mbcomment{We should also look at the literature for stochastic Stackelberg games}
    \item Krishnendu Chatterjee, Thomas A. Henzinger, Marcin Jurdzinski. Games with Secure Equilibria
    \item Julie De Pril, János Flesch, Jeroen Kuipers, Gijs Schoenmakers, Koos Vrieze. Existence of Secure Equilibrium in Multi-player Games with Perfect Information
    \item Anshul Gupta, Sven Schewe, and Dominik Wojtczak. Making the best of limited memory in multi-player discounted sum games
    \item Emmanuel Filiot, Raffaella Gentilini, and Jean-François Raskin. The Adversarial Stackelberg Value in Quantitative Games
\end{enumerate}}

\textbf{Structure of the Paper} In \cref{sec:prelim}, we introduce the necessary preliminaries for our definitions and developments. In \cref{sec:examples}, we examine the memory requirements of both players for playing their strategies. In \cref{sec:ThresholdProblem}, we consider the threshold problem, i.e. checking if $\mathbf{ASV}^{\epsilon} > c$. In \cref{sec:ComputeASV}, we present an algorithm to compute the $\mathbf{ASV}^{\epsilon}$. In \cref{sec:FMASV}, we present a memory improvement for a previous result established in \cite{FGR20}. In \cref{sec:Achievability}, we show that the $\mathbf{ASV}^{\epsilon}$ is always achievable.