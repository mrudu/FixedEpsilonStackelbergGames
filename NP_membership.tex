\begin{theorem}
    \label{ThmNpForASV}
    Given a mean-payoff game $\mathcal{G}$, a vertex $v \in V$, a rational value $c \in \mathbb{Q}$ and $\epsilon > 0$, it can be decided in non-deterministic polynomial time if $\mathbf{ASV}^{\epsilon}(v) > c$ and a finite memory strategy of Player~0 suffices for this threshold.
\end{theorem}

\noindent The rest of this \mychapter is devoted towards proving \textbf{\cref{ThmNpForASV}}. We start by stating a property of multi-dimensional mean-payoff games proved in \cite{VCDHRR15} that we rephrase here for a 2-dimensional game. This property expresses a bound on the weight of every finite play $\pi^f \in \mathbf{Out}_v(\sigma_0)$ where $\sigma_0$ is a memoryless winning strategy for Player~0.

\begin{lemma}
    \label{LemWeightPlayGrtThanC}
    In a mean-payoff game $\mathcal{G}$, if Player~0 wins $\underline{\mathbf{MP}}_0 < c \lor \underline{\mathbf{MP}}_1 < d$ from a vertex $v$ then he has a memoryless winning strategy $\sigma_0$ to do so, and there exist three constants $m_\mathcal{G}, c_\mathcal{G}, d_\mathcal{G} \in \mathbb{R}$ such that: $c_\mathcal{G} < c, d_\mathcal{G} < d$, and for all finite plays $\pi^f \in \mathbf{Out}_v(\sigma_0)$, i.e. starting in $v$ and compatible with $\sigma_0$, we have that:
    \begin{equation*}
        w_0(\pi^f) \leqslant m_\mathcal{G} + c_\mathcal{G} \times |\pi^f|
    \end{equation*}
    or
    \begin{equation*}
        w_1(\pi^f) \leqslant m_\mathcal{G} + d_\mathcal{G} \times |\pi^f|
    \end{equation*}
\end{lemma}

\noindent If Player~0 is to ensure that Player~1 does not deviate from a certain path $\pi$, Player~0 must ensure that from every vertex $v$ in $\pi$, $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \leqslant c \land \underline{\mathbf{MP}}_1 > d-\epsilon$. Using \textbf{\Cref{LemWeightPlayGrtThanC}}, we can now prove if Player~0 can ensure from a vertex $v$ that $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \leqslant c \land \underline{\mathbf{MP}}_1 > d-\epsilon$, then he can also ensure that $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \leqslant c \land \underline{\mathbf{MP}}_1 \geqslant d-\epsilon$. This is established in the following result.

\begin{lemma}
    \label{ConjGrtIsGrtEq}
    For every mean payoff game $\mathcal{G}$, for all vertices $v \in \mathcal{G}$, for all rational constants $c, d \in \mathbb{Q}$, we have that:
    \begin{equation*}
        v \models \ll 1 \gg \underline{\mathbf{MP}}_0 \geqslant c \land \underline{\mathbf{MP}}_1 > d
    \end{equation*}
    if and only if there exists a rational constant $d' \in \mathbb{Q}$, where $d' > d$ such that
    \begin{equation*}
        v \models \ll 1 \gg \underline{\mathbf{MP}}_0 \geqslant c \land \underline{\mathbf{MP}}_1 \geqslant d'
    \end{equation*}
\end{lemma}

\begin{proof}
    For the right to left direction of the proof, it is trivial to see that 
    % if $\underline{\mathbf{MP}}_1 > d'$ for some $d' > d$ then this implies $\underline{\mathbf{MP}}_1 \geqslant d$. Hence we get that 
    if $v \models \ll 1 \gg \underline{\mathbf{MP}}_0 \geqslant c \land \underline{\mathbf{MP}}_1 \geqslant d'$ for some $d' > d$, then we have that $v \models \ll 1 \gg \underline{\mathbf{MP}}_0 \geqslant c \land \underline{\mathbf{MP}}_1 > d$.

    For the left to right direction of the proof, we prove the contrapositive, i.e., we assume that $\forall d' > d$, we have $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \geqslant c \land \underline{\mathbf{MP}}_1 \geqslant d'$. Now we prove that $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \geqslant c \land \underline{\mathbf{MP}}_1 > d$.

    Since $\forall d'> d$, Player~1 loses $\underline{\mathbf{MP}}_0 \geqslant c \land \underline{\mathbf{MP}}_1 \geqslant d'$ from a given vertex $v$, due to determinacy of multi-dimensional mean-payoff games, Player~0 wins $\underline{\mathbf{MP}}_0 < c \lor \underline{\mathbf{MP}}_1 < d'$ from the same vertex $v$. By \textbf{\Cref{LemWeightPlayGrtThanC}}, we have that Player~0 has a memoryless strategy $\sigma_0$ to achieve the objective $\underline{\mathbf{MP}}_0 < c \lor \underline{\mathbf{MP}}_1 < d'$ from the vertex $v$. Note that in a finite game $\mathcal{G}$, Player~0 has only finitely many memoryless strategy. Therefore there must exist at least one strategy $\sigma_0^*$ that achieves the objective $v \models \ll 0 \gg \underline{\mathbf{MP}}_0 < c \lor \underline{\mathbf{MP}}_1 < d'$ for all $d' > d$. From \textbf{\Cref{LemWeightPlayGrtThanC}}, we also get three constants $m_\mathcal{G}, c_\mathcal{G}, d_\mathcal{G} \in \mathbb{R}$ such that for all $d' > d$, we have that $c_\mathcal{G} < c, d_\mathcal{G} < d'$ and for all finite plays $\pi^f \in \mathbf{Out}_v(\sigma_0^*)$, we have that
    \begin{equation*}
        w_0(\pi^f) \leqslant m_\mathcal{G} + c_\mathcal{G} \times |\pi^f|
    \end{equation*}
    or we have that
    \begin{equation*}
        w_1(\pi^f) \leqslant m_\mathcal{G} + d_\mathcal{G} \times |\pi^f|
    \end{equation*}

    Now, for every play $\pi \in \mathbf{Out}_v(\sigma_0^*)$, we know that $|\pi| \to \infty$. Thus, we get that:
    \begin{equation*}
        \underline{\mathbf{MP}}_0(\pi) = \frac{w_0(\pi)}{|\pi|} \leqslant \frac{m_\mathcal{G}}{|\pi|} + c_\mathcal{G}
    \end{equation*}
    or we have that
    \begin{equation*}
        \underline{\mathbf{MP}}_1(\pi) = \frac{w_1(\pi)}{|\pi|} \leqslant \frac{m_\mathcal{G}}{|\pi|} + d_\mathcal{G}
    \end{equation*}

    Since $|\pi| \to \infty$, the constant $\frac{m_\mathcal{G}}{|\pi|} \to 0$. Thus, we get $v \models \ll 0 \gg \underline{\mathbf{MP}}_0(\pi) \leqslant c_\mathcal{G} \lor \underline{\mathbf{MP}}_1(\pi) \leqslant d_\mathcal{G}$. Since we know that $c_\mathcal{G} < c, d_\mathcal{G} < d'$, we get that $v \models \ll 0 \gg \underline{\mathbf{MP}}_0(\pi) < c \lor \underline{\mathbf{MP}}_1(\pi) < d'$ for every $d' > d$. Thus, we get that  $v \models \ll 0 \gg \underline{\mathbf{MP}}_0(\pi) < c \lor \underline{\mathbf{MP}}_1(\pi) \leqslant d$. Therefore, by determinacy of multi-dimensional mean-payoff games, we have that $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \geqslant c \land \underline{\mathbf{MP}}_1 > d$.
\end{proof}

\textbf{Modified Game} We now construct a game $\mathcal{G'}$ from the given game $\mathcal{G}$ by multiplying the first dimension on each edge by -1. It is easy to see that, for all vertices $v$ in $\mathcal{G}$, we have that $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \leqslant c \land \underline{\mathbf{MP}}_1 > d-\epsilon$ if and only if for the same vertex $v$ in the game $\mathcal{G'}$, we have $v \nvDash \ll 1 \gg \overline{\mathbf{MP}}_0 \geqslant -c \land \underline{\mathbf{MP}}_1 > d-\epsilon$ for some value $d \in \mathbb{Q}$. From \textbf{\cref{ConjGrtIsGrtEq}}, for the same vertex $v$, we have $v \nvDash \ll 1 \gg \overline{\mathbf{MP}}_0 \geqslant -c \land \underline{\mathbf{MP}}_1 \geqslant d'$, for some $d' \in \mathbb{R}$ and $d' > d - \epsilon$. \\ \noindent
We modify the game $\mathcal{G'}$ further by adding $c$ to the first dimension and subtracting $d'$ from the second dimension for all the edges in the game. Note that the edges and the vertices of both games $\mathcal{G}$ and $\mathcal{G'}$ are the same, the only difference between the two games being their edge weights.

\noindent The following proposition states that the set of winning strategies for both Player~0 and Player~1 are the same in the games $\mathcal{G}$ and $\mathcal{G'}$.

\begin{proposition}
    \label{PropGamStrEqNewGamStr}
    For every vertex $v \in V$ in the game $\mathcal{G'}$, Player~0 (Player~1) can ensure that $v \nvDash \ll 1 \gg \overline{\mathbf{MP}}_0 \geqslant 0 \land \underline{\mathbf{MP}}_1 \geqslant 0$ ($v \models \ll 1 \gg \overline{\mathbf{MP}}_0 \geqslant 0 \land \underline{\mathbf{MP}}_1 \geqslant 0$) with a strategy $\sigma_0^{v}$ ($\sigma_1^{v}$) if and only if Player~0 (Player~1) can ensure that $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \leqslant c \land \underline{\mathbf{MP}}_1 > d-\epsilon$ ($v \models \ll 1 \gg \underline{\mathbf{MP}}_0 \leqslant c \land \underline{\mathbf{MP}}_1 > d-\epsilon$) with the same strategy $\sigma_0^{v}$ ($\sigma_1^{v}$) from vertex $v$ in the game $\mathcal{G}$.
\end{proposition}

\noindent We also refer to the following result for Multi-weighted two-player games with $\mathbf{MeanPayoffInfSup}$ objective \cite{VCDHRR15}. This result establishes that if Player~0 can ensure that Player~1 does not satisfy the $\mathbf{MeanPayoffInfSup}$ objective from a vertex $v$, then she has a memoryless strategy for doing so.

\begin{theorem}
    \label{ThmMemlessStrForP2}
    \textbf{\emph{(Theorem 8 in \cite{VCDHRR15})}} For multi-dimensional two-player mean-payoff games with objective \\
    $\mathbf{MeanPayoffInfSup}(I,J) = \{\pi' \in \mathbf{Plays}(\mathcal{G}) \mid \forall i \in I : \underline{\mathbf{MP}}(\pi')_i \geqslant 0 \text{ and } \forall j \in J : \overline{\mathbf{MP}}(\pi')_j \geqslant 0\}$ for Player~1, the following assertions hold:
    \begin{enumerate}
        \item Winning strategies for Player~1 require infinite-memory in general, and memoryless winning strategies exist for Player~0. \footnote{Player~0 is called Player 2 in \cite{FGR20}}
        \item The problem of deciding whether a given vertex is winning for Player~1 is coNP-complete.
    \end{enumerate}
\end{theorem}
 
\begin{proof}[Proof of \textbf{\Cref{ThmNpForASV}}]
According to the \textbf{\cref{LemPlaysAsWitnessForASV}}, we consider a non-deterministic Turing machine that establishes the membership to $\mathbf{NP}$ by guessing a reachable SCC $S$, a finite play $\pi_1$ to reach $S$ from $v$, two simple cycles $l_1, l_2$, along with two finite plays $\pi_2$ and $\pi_3$ that connects the two simple cycles, and parameters $\alpha, \beta \in \mathbb{Q}^{+}$. Note that the parameters $\alpha , \beta$ can be obtained by solving a linear program. Since linear programs are solvable in polynomial time, the values $\alpha$ and $\beta$ have polynomial size representation. Additionally, for each vertex $v'$ that appear along the plays $\pi_1, \pi_2$ and $\pi_3$, and on the simple cycles $l_1$ and $l_2$, the turing machine guesses a memoryless strategy $\sigma_0^{v'}$ for Player~0 that establishes $v' \nvDash \ll 1 \gg \underline{\textbf{MP}}_0 \leqslant c \land \underline{\textbf{MP}}_1 > d - \epsilon$ which means by determinacy of multi-dimensional mean-payoff games, that $v' \models \ll 0 \gg \underline{\textbf{MP}}_0 > c \lor \underline{\textbf{MP}}_1 \leqslant d - \epsilon$.

Addtionally, note that from \textbf{\cref{LemPlaysAsWitnessForASV}}, we can obtain a $\epsilon$-regular-witness $\pi'$. Using $\pi'$, we build a finite memory strategy $\sigma_0^v$ for Player~0 as stated below:
\begin{enumerate}
    \item Player~0 follows $\pi'$ if Player~1 does not deviate from $\pi'$. The finite memory strategy stems from the finite $k$ as required in the four cases mentioned above.
    \item For each vertex $v \in \pi'$, Player~0 employs a memoryless strategy that establishes $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \leqslant c \land \underline{\mathbf{MP}}_1 > d-\epsilon$.
\end{enumerate}

We shall now establish the existence of these memoryless strategies. 
We start by construction of a modified mean-payoff game $\mathcal{G'}$ from the given game $\mathcal{G}$. Now, we get a modified objective for Player~0 in $\mathcal{G'}$, i.e., to get a memoryless strategy for Player~0 for all vertices $v \in \pi_1, \pi_2, \pi_3, l_1, l_2$ such that $v \nvDash \ll 1 \gg \overline{\mathbf{MP}}_0 \geqslant 0 \land \underline{\mathbf{MP}}_1 \geqslant 0$. The existence of a memoryless strategy for Player~0 which ensures her objective follows from \textbf{\Cref{ThmMemlessStrForP2}}

\noindent We formulate $\mathcal{G'}$ as a multi-weighted two-player game structure specified in \textbf{\cref{ThmMemlessStrForP2}} with $I = \{1\}$ and $J = \{0\}$.
Thus, by \textbf{\cref{PropGamStrEqNewGamStr}}, if Player~0 has a strategy $\sigma_0^{v}$ to ensure $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \leqslant c \land \underline{\mathbf{MP}}_1 > d-\epsilon$ from every vertex $v \in \pi_1, \pi_2, \pi_3, l_1, l_2$, the same strategy $\sigma_0^{v}$for every vertex $v$ appearing in $\pi_1, \pi_2, \pi_3, l_1, \text{ and } l_2$ in the game $\mathcal{G'}$ ensures $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \geqslant 0 \land \underline{\mathbf{MP}}_1 \geqslant 0$. 
By \textbf{\cref{ThmMemlessStrForP2}}, since Player~0 wins the game $\mathcal{G}'$ from every vertex $v$ in $\pi_1, \pi_2, \pi_3, l_1, s \text{ and } l_2$, she has a memoryless strategy $\sigma_0^{v}$ to do so thus ensuring that $v \nvDash \ll 1 \gg \underline{\mathbf{MP}}_0 \leqslant c \land \underline{\mathbf{MP}}_1 > d - \epsilon$. 
There are polynomially many vertices, and the memoryless strategy $\sigma_0^{v}$ is checkable in $\mathsf{PTime}$ ensuring that the vertices along $\pi_1, \pi_2, \pi_3$ and $l_1, l_2$ are not $(c,d)^\epsilon$-bad, where $d = \alpha \cdot w_1(l_1) + \beta \cdot w_1(l_2)$.
\end{proof}